{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indirect-jordan",
   "metadata": {},
   "source": [
    "# Question Answwering, QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-canvas",
   "metadata": {},
   "source": [
    "* 개요 : 페이스북에서 공개한 Babi QA 셋을 메모리 네트워크를 통해 풀어보고, BERT를 이용하여 MRC(기계 독해 이해력) 테스트인 스쿼드(SQuAD, Stanford Question Answering Dataset)를 풀어본다.\n",
    "\n",
    "* 출처 : WikiDocs, <딥 러닝을 이용한 자연어 처리 입문>, https://wikidocs.net/82475"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-alaska",
   "metadata": {},
   "source": [
    "## 메모리 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-tackle",
   "metadata": {},
   "source": [
    "Input : 스토리 문장(Value, Key), 질문 문장(Query)\n",
    "\n",
    "Embedding : 문장 내 각 단어가 임베딩 되어 각 단어가 임베딩 벡터로 변환\n",
    "\n",
    "스토리 문장 표현 : 내적(dot product)을 통해, 임베딩된 Query는 Key와 유사도를 구하고, 소프트맥스 함수를 통해 값을 정규화하여 Value에 더해서 유사도 값을 반영 (어텐션 매커니즘)\n",
    "\n",
    "연결(Concatenate) : 스토리 문장 표현을 질문 문장을 임베딩한 질문 표현과 연결하고, LSTM과 밀집층(dense layer)의 입력으로 사용하여 정답 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-swimming",
   "metadata": {},
   "source": [
    "## Babi 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-perry",
   "metadata": {},
   "source": [
    "* Babi 데이터셋 : https://research.fb.com/downloads/babi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "digital-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "appreciated-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                'babi_tasks_1-20_v1-2.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "controversial-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    " with tarfile.open(path) as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italic-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Mary moved to the bathroom.\n",
      "2 John went to the hallway.\n",
      "3 Where is Mary? \tbathroom\t1\n",
      "4 Daniel went back to the hallway.\n",
      "5 Sandra moved to the garden.\n",
      "6 Where is Daniel? \thallway\t4\n",
      "7 John moved to the office.\n",
      "8 Sandra journeyed to the bathroom.\n",
      "9 Where is Daniel? \thallway\t4\n",
      "10 Mary moved to the hallway.\n",
      "11 Daniel travelled to the office.\n",
      "12 Where is Daniel? \toffice\t11\n",
      "13 John went back to the garden.\n",
      "14 John moved to the bedroom.\n",
      "15 Where is Sandra? \tbathroom\t8\n",
      "1 Sandra travelled to the office.\n",
      "2 Sandra went to the bathroom.\n",
      "3 Where is Sandra? \tbathroom\t2\n",
      "4 Mary went to the bedroom.\n",
      "5 Daniel moved to the hallway.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()  # .strip() : 문자열에서 양 쪽 공백 제거\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "twelve-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "\n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "german-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabulous-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consolidated-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 스토리의 개수 : 10000\n",
      "훈련용 질문의 개수 : 10000\n",
      "훈련용 답변의 개수 : 10000\n",
      "테스트용 스토리의 개수 : 1000\n",
      "테스트용 질문의 개수 : 1000\n",
      "테스트용 답변의 개수 : 1000\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 스토리의 개수 :', len(train_stories))\n",
    "print('훈련용 질문의 개수 :',len(train_questions))\n",
    "print('훈련용 답변의 개수 :',len(train_answers))\n",
    "print('테스트용 스토리의 개수 :',len(test_stories))\n",
    "print('테스트용 질문의 개수 :',len(test_questions))\n",
    "print('테스트용 답변의 개수 :',len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "corrected-determination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John went back to the garden.',\n",
       " 'Mary went to the kitchen.',\n",
       " 'Sandra went back to the bedroom.',\n",
       " 'John travelled to the bedroom.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cutting-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where is John? '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "numerous-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bedroom'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "personal-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split('(\\W+)', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "automatic-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "\n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "\n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어 집합 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "proved-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "criminal-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "joined-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "warming-mills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 68\n",
      "질문의 최대 길이 : 4\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "broadband-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "        # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "celtic-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "french-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-zambia",
   "metadata": {},
   "source": [
    "## 메모리 네트워크로 QA 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "drawn-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "minus-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cellular-manchester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 플레이스 홀더. 입력을 담는 변수\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    "\n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "foster-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    "\n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fundamental-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "green-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "iraqi-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation/truediv:0', description=\"created by layer 'activation'\")\n",
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ordinary-triple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 68)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 50)     1100        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 4, 50)        1100        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 68, 4)        0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 4)      88          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 118)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           46848       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 22)           1430        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 50,566\n",
      "Trainable params: 50,566\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n",
      "313/313 [==============================] - 6s 9ms/step - loss: 2.0135 - acc: 0.1540 - val_loss: 1.7778 - val_acc: 0.1870\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.7262 - acc: 0.2446 - val_loss: 1.6487 - val_acc: 0.3290\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.5708 - acc: 0.3666 - val_loss: 1.4865 - val_acc: 0.4020\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.4981 - acc: 0.4108 - val_loss: 1.4565 - val_acc: 0.4420\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.4776 - acc: 0.4266 - val_loss: 1.3919 - val_acc: 0.4940\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3942 - acc: 0.4777 - val_loss: 1.3265 - val_acc: 0.4990\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3649 - acc: 0.4833 - val_loss: 1.3270 - val_acc: 0.5070\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3190 - acc: 0.5059 - val_loss: 1.2789 - val_acc: 0.5180\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3055 - acc: 0.5101 - val_loss: 1.2793 - val_acc: 0.5110\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2819 - acc: 0.5056 - val_loss: 1.2430 - val_acc: 0.5220\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2577 - acc: 0.5114 - val_loss: 1.1977 - val_acc: 0.5200\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2320 - acc: 0.5067 - val_loss: 1.1966 - val_acc: 0.5080\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2207 - acc: 0.5068 - val_loss: 1.1876 - val_acc: 0.5100\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1853 - acc: 0.5256 - val_loss: 1.1703 - val_acc: 0.5190\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1831 - acc: 0.5175 - val_loss: 1.1805 - val_acc: 0.5170\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1551 - acc: 0.5261 - val_loss: 1.1575 - val_acc: 0.5200\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1470 - acc: 0.5217 - val_loss: 1.1715 - val_acc: 0.5010\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1400 - acc: 0.5352 - val_loss: 1.1496 - val_acc: 0.5110\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1362 - acc: 0.5355 - val_loss: 1.1556 - val_acc: 0.5080\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1427 - acc: 0.5313 - val_loss: 1.1651 - val_acc: 0.5200\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1249 - acc: 0.5409 - val_loss: 1.1503 - val_acc: 0.5270\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1069 - acc: 0.5369 - val_loss: 1.1440 - val_acc: 0.5090\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1130 - acc: 0.5253 - val_loss: 1.1573 - val_acc: 0.5080\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1003 - acc: 0.5383 - val_loss: 1.1304 - val_acc: 0.5050\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0973 - acc: 0.5427 - val_loss: 1.1516 - val_acc: 0.5240\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0861 - acc: 0.5481 - val_loss: 1.1406 - val_acc: 0.5020\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0879 - acc: 0.5382 - val_loss: 1.1419 - val_acc: 0.5120\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0813 - acc: 0.5507 - val_loss: 1.1665 - val_acc: 0.5150\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0648 - acc: 0.5501 - val_loss: 1.1549 - val_acc: 0.5160\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0604 - acc: 0.5478 - val_loss: 1.1602 - val_acc: 0.5170\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0604 - acc: 0.5458 - val_loss: 1.1539 - val_acc: 0.5100\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0430 - acc: 0.5542 - val_loss: 1.1345 - val_acc: 0.5220\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0447 - acc: 0.5630 - val_loss: 1.1229 - val_acc: 0.5150\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0094 - acc: 0.5727 - val_loss: 1.0618 - val_acc: 0.5700\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.9227 - acc: 0.6342 - val_loss: 0.8214 - val_acc: 0.7080\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7133 - acc: 0.7479 - val_loss: 0.6747 - val_acc: 0.7440\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6205 - acc: 0.7770 - val_loss: 0.6340 - val_acc: 0.7630\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5419 - acc: 0.8003 - val_loss: 0.5727 - val_acc: 0.7720\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5253 - acc: 0.8049 - val_loss: 0.4964 - val_acc: 0.8020\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4385 - acc: 0.8442 - val_loss: 0.4464 - val_acc: 0.8330\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3843 - acc: 0.8605 - val_loss: 0.4170 - val_acc: 0.8400\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3701 - acc: 0.8663 - val_loss: 0.3912 - val_acc: 0.8530\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3392 - acc: 0.8739 - val_loss: 0.3769 - val_acc: 0.8520\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3200 - acc: 0.8835 - val_loss: 0.3628 - val_acc: 0.8570\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3000 - acc: 0.8886 - val_loss: 0.3655 - val_acc: 0.8660\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2909 - acc: 0.8912 - val_loss: 0.3971 - val_acc: 0.8430\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2787 - acc: 0.8944 - val_loss: 0.3652 - val_acc: 0.8530\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2648 - acc: 0.9017 - val_loss: 0.3456 - val_acc: 0.8700\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2630 - acc: 0.8991 - val_loss: 0.3497 - val_acc: 0.8670\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2370 - acc: 0.9096 - val_loss: 0.3394 - val_acc: 0.8820\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2348 - acc: 0.9140 - val_loss: 0.3314 - val_acc: 0.8860\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2146 - acc: 0.9241 - val_loss: 0.2991 - val_acc: 0.8850\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2026 - acc: 0.9248 - val_loss: 0.2794 - val_acc: 0.8970\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2013 - acc: 0.9302 - val_loss: 0.2575 - val_acc: 0.9020\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1806 - acc: 0.9375 - val_loss: 0.2416 - val_acc: 0.9130\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1609 - acc: 0.9395 - val_loss: 0.2667 - val_acc: 0.9020\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1557 - acc: 0.9439 - val_loss: 0.2378 - val_acc: 0.9210\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1496 - acc: 0.9496 - val_loss: 0.2206 - val_acc: 0.9290\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1332 - acc: 0.9510 - val_loss: 0.2323 - val_acc: 0.9260\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1208 - acc: 0.9595 - val_loss: 0.2080 - val_acc: 0.9300\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1195 - acc: 0.9594 - val_loss: 0.2040 - val_acc: 0.9350\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1195 - acc: 0.9604 - val_loss: 0.2183 - val_acc: 0.9330\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1198 - acc: 0.9603 - val_loss: 0.2323 - val_acc: 0.9290\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1108 - acc: 0.9617 - val_loss: 0.2171 - val_acc: 0.9390\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1010 - acc: 0.9662 - val_loss: 0.2006 - val_acc: 0.9350\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1042 - acc: 0.9635 - val_loss: 0.1921 - val_acc: 0.9400\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1051 - acc: 0.9630 - val_loss: 0.2099 - val_acc: 0.9310\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0864 - acc: 0.9704 - val_loss: 0.2069 - val_acc: 0.9390\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0890 - acc: 0.9691 - val_loss: 0.2023 - val_acc: 0.9360\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0832 - acc: 0.9700 - val_loss: 0.2010 - val_acc: 0.9360\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0776 - acc: 0.9745 - val_loss: 0.2004 - val_acc: 0.9340\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0677 - acc: 0.9769 - val_loss: 0.2167 - val_acc: 0.9320\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0633 - acc: 0.9787 - val_loss: 0.2080 - val_acc: 0.9390\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0670 - acc: 0.9765 - val_loss: 0.2052 - val_acc: 0.9370\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0750 - acc: 0.9761 - val_loss: 0.1885 - val_acc: 0.9400\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0616 - acc: 0.9783 - val_loss: 0.2174 - val_acc: 0.9300\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0716 - acc: 0.9768 - val_loss: 0.1917 - val_acc: 0.9430\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0683 - acc: 0.9765 - val_loss: 0.2042 - val_acc: 0.9390\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0679 - acc: 0.9783 - val_loss: 0.1990 - val_acc: 0.9400\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0533 - acc: 0.9814 - val_loss: 0.2446 - val_acc: 0.9410\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0488 - acc: 0.9833 - val_loss: 0.2004 - val_acc: 0.9380\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0574 - acc: 0.9827 - val_loss: 0.2042 - val_acc: 0.9330\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0652 - acc: 0.9786 - val_loss: 0.1938 - val_acc: 0.9460\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0583 - acc: 0.9820 - val_loss: 0.2490 - val_acc: 0.9390\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0426 - acc: 0.9854 - val_loss: 0.1961 - val_acc: 0.9350\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0567 - acc: 0.9836 - val_loss: 0.1890 - val_acc: 0.9440\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0585 - acc: 0.9832 - val_loss: 0.1912 - val_acc: 0.9510\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0630 - acc: 0.9833 - val_loss: 0.1651 - val_acc: 0.9480\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0485 - acc: 0.9846 - val_loss: 0.1940 - val_acc: 0.9410\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0418 - acc: 0.9869 - val_loss: 0.1813 - val_acc: 0.9450\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0381 - acc: 0.9883 - val_loss: 0.1825 - val_acc: 0.9470\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0508 - acc: 0.9842 - val_loss: 0.2173 - val_acc: 0.9410\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0426 - acc: 0.9865 - val_loss: 0.2157 - val_acc: 0.9410\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0446 - acc: 0.9881 - val_loss: 0.1964 - val_acc: 0.9450\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0370 - acc: 0.9894 - val_loss: 0.1842 - val_acc: 0.9430\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0422 - acc: 0.9872 - val_loss: 0.1967 - val_acc: 0.9450\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0432 - acc: 0.9883 - val_loss: 0.1983 - val_acc: 0.9490\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0401 - acc: 0.9884 - val_loss: 0.1908 - val_acc: 0.9560\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0312 - acc: 0.9880 - val_loss: 0.2156 - val_acc: 0.9460\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0368 - acc: 0.9875 - val_loss: 0.2307 - val_acc: 0.9460\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0362 - acc: 0.9890 - val_loss: 0.2055 - val_acc: 0.9440\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0329 - acc: 0.9911 - val_loss: 0.2022 - val_acc: 0.9490\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0308 - acc: 0.9895 - val_loss: 0.2110 - val_acc: 0.9450\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0349 - acc: 0.9891 - val_loss: 0.2240 - val_acc: 0.9490\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.2135 - val_acc: 0.9490\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0277 - acc: 0.9907 - val_loss: 0.2120 - val_acc: 0.9500\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0349 - acc: 0.9897 - val_loss: 0.2095 - val_acc: 0.9500\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0419 - acc: 0.9899 - val_loss: 0.1821 - val_acc: 0.9550\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0285 - acc: 0.9930 - val_loss: 0.1964 - val_acc: 0.9480\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0352 - acc: 0.9905 - val_loss: 0.2392 - val_acc: 0.9380\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.2217 - val_acc: 0.9500\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0308 - acc: 0.9925 - val_loss: 0.2302 - val_acc: 0.9440\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0309 - acc: 0.9917 - val_loss: 0.2315 - val_acc: 0.9470\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.2040 - val_acc: 0.9520\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0311 - acc: 0.9903 - val_loss: 0.2085 - val_acc: 0.9500\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0330 - acc: 0.9917 - val_loss: 0.2110 - val_acc: 0.9480\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0380 - acc: 0.9909 - val_loss: 0.2085 - val_acc: 0.9500\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0253 - acc: 0.9925 - val_loss: 0.2101 - val_acc: 0.9530\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0318 - acc: 0.9907 - val_loss: 0.2002 - val_acc: 0.9540\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0338 - acc: 0.9925 - val_loss: 0.2141 - val_acc: 0.9520\n"
     ]
    }
   ],
   "source": [
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# start training the model\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    "\n",
    "# save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "attended-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2141 - acc: 0.9520\n",
      "\n",
      " 테스트 정확도: 0.9520\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "tutorial-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-russian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
