{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "white-livestock",
   "metadata": {},
   "source": [
    "# MemN QA Kor(MemN으로 한국어 QA 해보기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-gregory",
   "metadata": {},
   "source": [
    "출처 : WikiDocs, <딥 러닝을 이용한 자연어 처리 입문>, https://wikidocs.net/85470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-matthew",
   "metadata": {},
   "source": [
    "## 커스터마이즈드 KoNLPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-radio",
   "metadata": {},
   "source": [
    "Customized Konlpy : 사용자 사전 추가가 매우 쉬운 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "copyrighted-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: customized_konlpy in c:\\users\\soyeon\\python2021\\lib\\site-packages (0.0.64)\n",
      "Requirement already satisfied: Jpype1>=0.6.1 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from customized_konlpy) (1.2.0)\n",
      "Requirement already satisfied: konlpy>=0.4.4 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from customized_konlpy) (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (3.10.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (4.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (4.6.2)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (1.19.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\soyeon\\python2021\\lib\\site-packages (from konlpy>=0.4.4->customized_konlpy) (0.4.4)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.26.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\soyeon\\python2021\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy>=0.4.4->customized_konlpy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "combined-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은', '경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# customized _konlpy에서 제공하는 형태소 분석기 Twitter를 사용하여 토큰화해보자!\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emerging-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 Twitter에 사전 추가\n",
    "twitter.add_dictionary('은경이', 'Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "computational-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은경이', '는', '사무실', '로', '갔습니다', '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.morphs('은경이는 사무실로 갔습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-circumstances",
   "metadata": {},
   "source": [
    "## 한국어 Babi 데이터셋 로드와 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-arbor",
   "metadata": {},
   "source": [
    "데이터 출처\n",
    "\n",
    "훈련 데이터 : https://bit.ly/31SqtHy\n",
    "\n",
    "테스트 데이터 : https://bit.ly/3f7rH5g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinguished-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = os.path.join(\"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(\"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n",
      "1 경임이는 사무실로 가버렸습니다.\n",
      "2 경임이는 화장실로 이동했습니다.\n",
      "3 경임이는 어디야? \t화장실\t2\n",
      "4 필웅이는 침실로 이동했습니다.\n",
      "5 수종이는 복도로 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 상위 20개 문장 출력\n",
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "random-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "\n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upset-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "technical-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 구성 확인 - 스토리, 질문, 답변\n",
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occupied-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 스토리의 개수 : 10000\n",
      "훈련용 질문의 개수 : 10000\n",
      "훈련용 답변의 개수 : 10000\n",
      "테스트용 스토리의 개수 : 1000\n",
      "테스트용 질문의 개수 : 1000\n",
      "테스트용 답변의 개수 : 1000\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 스토리의 개수 :', len(train_stories))\n",
    "print('훈련용 질문의 개수 :',len(train_questions))\n",
    "print('훈련용 답변의 개수 :',len(train_answers))\n",
    "print('테스트용 스토리의 개수 :',len(test_stories))\n",
    "print('테스트용 질문의 개수 :',len(test_questions))\n",
    "print('테스트용 답변의 개수 :',len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "iraqi-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['은경이는 부엌으로 가버렸습니다.',\n",
       " '필웅이는 사무실로 가버렸습니다.',\n",
       " '수종이는 복도로 뛰어갔습니다.',\n",
       " '은경이는 사무실로 복귀했습니다.',\n",
       " '경임이는 사무실로 이동했습니다.',\n",
       " '경임이는 침실로 갔습니다.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alien-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'은경이는 어디야? '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[3572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "innocent-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사무실'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[3572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "noble-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 정의\n",
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split('(\\W+)', sent) if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mental-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary 만드는 함수 정의\n",
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "\n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "\n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어 집합 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sought-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "peaceful-wayne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "therapeutic-bradley",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\soyeon\\python2021\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['은', '경이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
      "['경', '임', '이', '는', '정원', '으로', '가버렸습니다', '.']\n",
      "['수종', '이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
      "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
      "['수종', '이', '는', '사무실', '로', '갔습니다', '.']\n",
      "['은', '경이', '는', '침실', '로', '갔습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석기 사용하여 원하는 결과가 정상적으로 출력되는지 확인\n",
    "twitter = Twitter()\n",
    "\n",
    "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
    "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
    "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
    "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
    "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
    "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "developmental-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 추가\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('수종이', 'Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accessory-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['은경이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
      "['경임이', '는', '정원', '으로', '가버렸습니다', '.']\n",
      "['수종이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
      "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
      "['수종이', '는', '사무실', '로', '갔습니다', '.']\n",
      "['은경이', '는', '침실', '로', '갔습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
    "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
    "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
    "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
    "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
    "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "forced-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 새로운 토큰화 함수로 정의\n",
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "postal-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "grateful-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "english-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합의 크기 정의\n",
    "vocab_size = len(word2idx) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "experimental-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 70\n",
      "질문의 최대 길이 : 5\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "western-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "        # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hearing-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spiritual-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70) (10000, 5) (10000, 24) (1000, 70) (1000, 5) (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-invention",
   "metadata": {},
   "source": [
    "## 메모리 네트워크로 QA 태스크 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "quick-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "opponent-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "utility-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 70), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 플레이스 홀더. 입력을 담는 변수\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    "\n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "virtual-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    "\n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "weird-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "liquid-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 70, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 70, 5), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 5, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "exact-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 70, 5), dtype=tf.float32, name=None), name='activation/truediv:0', description=\"created by layer 'activation'\")\n",
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 5, 70), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 5, 120), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wired-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 50)     1200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 5, 50)        1200        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 70, 5)        0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 70, 5)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 5)      120         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 70, 5)        0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 5, 70)        0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 120)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           47360       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           1560        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 51,440\n",
      "Trainable params: 51,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n",
      "313/313 [==============================] - 6s 10ms/step - loss: 2.0227 - acc: 0.1656 - val_loss: 1.7461 - val_acc: 0.2270\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.7086 - acc: 0.2464 - val_loss: 1.6257 - val_acc: 0.2690\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.6320 - acc: 0.2944 - val_loss: 1.5693 - val_acc: 0.3650\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.5316 - acc: 0.3765 - val_loss: 1.4554 - val_acc: 0.4400\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.4941 - acc: 0.4008 - val_loss: 1.4381 - val_acc: 0.4610\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4722 - acc: 0.4300 - val_loss: 1.3946 - val_acc: 0.4700\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4143 - acc: 0.4662 - val_loss: 1.3336 - val_acc: 0.5150\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3454 - acc: 0.4992 - val_loss: 1.3165 - val_acc: 0.5220\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3053 - acc: 0.5085 - val_loss: 1.2606 - val_acc: 0.5360\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2759 - acc: 0.5241 - val_loss: 1.2428 - val_acc: 0.5350\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2393 - acc: 0.5256 - val_loss: 1.2708 - val_acc: 0.5250\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2553 - acc: 0.5113 - val_loss: 1.2530 - val_acc: 0.5330\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2123 - acc: 0.5295 - val_loss: 1.2523 - val_acc: 0.5180\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1920 - acc: 0.5273 - val_loss: 1.2063 - val_acc: 0.5370\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1876 - acc: 0.5273 - val_loss: 1.2223 - val_acc: 0.5300\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1971 - acc: 0.5187 - val_loss: 1.2349 - val_acc: 0.5320\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1589 - acc: 0.5451 - val_loss: 1.1997 - val_acc: 0.5270\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1534 - acc: 0.5424 - val_loss: 1.1982 - val_acc: 0.5510\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1366 - acc: 0.5612 - val_loss: 1.1404 - val_acc: 0.5890\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0779 - acc: 0.5910 - val_loss: 1.1198 - val_acc: 0.5890\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0642 - acc: 0.6154 - val_loss: 1.0596 - val_acc: 0.6250\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0336 - acc: 0.6142 - val_loss: 1.0091 - val_acc: 0.6380\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9565 - acc: 0.6522 - val_loss: 0.9866 - val_acc: 0.6490\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9154 - acc: 0.6679 - val_loss: 0.9054 - val_acc: 0.6980\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.8541 - acc: 0.7013 - val_loss: 0.8577 - val_acc: 0.7030\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7702 - acc: 0.7240 - val_loss: 0.7517 - val_acc: 0.7360\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.7211 - acc: 0.7510 - val_loss: 0.7181 - val_acc: 0.7500\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6559 - acc: 0.7718 - val_loss: 0.6791 - val_acc: 0.7620\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6257 - acc: 0.7816 - val_loss: 0.6612 - val_acc: 0.7680\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5839 - acc: 0.7904 - val_loss: 0.6405 - val_acc: 0.7770\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5821 - acc: 0.7897 - val_loss: 0.6170 - val_acc: 0.7800\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5476 - acc: 0.8032 - val_loss: 0.6189 - val_acc: 0.7800\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5289 - acc: 0.8155 - val_loss: 0.5860 - val_acc: 0.7830\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5146 - acc: 0.8135 - val_loss: 0.5980 - val_acc: 0.7800\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4958 - acc: 0.8245 - val_loss: 0.5757 - val_acc: 0.8070\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4765 - acc: 0.8277 - val_loss: 0.5814 - val_acc: 0.8050\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4820 - acc: 0.8308 - val_loss: 0.5449 - val_acc: 0.8090\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4464 - acc: 0.8424 - val_loss: 0.5357 - val_acc: 0.8110\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4438 - acc: 0.8414 - val_loss: 0.5186 - val_acc: 0.8140\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4313 - acc: 0.8499 - val_loss: 0.5244 - val_acc: 0.8140\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4225 - acc: 0.8507 - val_loss: 0.5091 - val_acc: 0.8180\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4128 - acc: 0.8571 - val_loss: 0.5083 - val_acc: 0.8140\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3841 - acc: 0.8642 - val_loss: 0.5129 - val_acc: 0.8040\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3860 - acc: 0.8670 - val_loss: 0.4731 - val_acc: 0.8320\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3551 - acc: 0.8749 - val_loss: 0.4699 - val_acc: 0.8330\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3524 - acc: 0.8689 - val_loss: 0.4833 - val_acc: 0.8270\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3667 - acc: 0.8694 - val_loss: 0.4659 - val_acc: 0.8270\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3441 - acc: 0.8791 - val_loss: 0.4784 - val_acc: 0.8300\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3290 - acc: 0.8826 - val_loss: 0.4881 - val_acc: 0.8390\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3431 - acc: 0.8743 - val_loss: 0.4537 - val_acc: 0.8380\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3130 - acc: 0.8876 - val_loss: 0.4458 - val_acc: 0.8400\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3227 - acc: 0.8855 - val_loss: 0.4705 - val_acc: 0.8410\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3047 - acc: 0.8885 - val_loss: 0.4484 - val_acc: 0.8440\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2956 - acc: 0.8916 - val_loss: 0.4668 - val_acc: 0.8340\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2964 - acc: 0.8896 - val_loss: 0.4803 - val_acc: 0.8390\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2903 - acc: 0.8908 - val_loss: 0.4681 - val_acc: 0.8440\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2829 - acc: 0.8990 - val_loss: 0.5137 - val_acc: 0.8310\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2634 - acc: 0.9074 - val_loss: 0.4528 - val_acc: 0.8460\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2592 - acc: 0.9061 - val_loss: 0.4413 - val_acc: 0.8430\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2745 - acc: 0.9023 - val_loss: 0.5076 - val_acc: 0.8350\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2687 - acc: 0.9053 - val_loss: 0.5064 - val_acc: 0.8420\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2547 - acc: 0.9125 - val_loss: 0.4644 - val_acc: 0.8440\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2512 - acc: 0.9100 - val_loss: 0.4843 - val_acc: 0.8430\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2459 - acc: 0.9147 - val_loss: 0.4726 - val_acc: 0.8370\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2360 - acc: 0.9186 - val_loss: 0.4701 - val_acc: 0.8440\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2260 - acc: 0.9150 - val_loss: 0.4803 - val_acc: 0.8460\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2254 - acc: 0.9203 - val_loss: 0.4972 - val_acc: 0.8380\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2188 - acc: 0.9233 - val_loss: 0.4824 - val_acc: 0.8440\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2302 - acc: 0.9149 - val_loss: 0.4841 - val_acc: 0.8440\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2232 - acc: 0.9224 - val_loss: 0.4901 - val_acc: 0.8380\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1983 - acc: 0.9276 - val_loss: 0.5153 - val_acc: 0.8420\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1984 - acc: 0.9319 - val_loss: 0.4721 - val_acc: 0.8510\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1903 - acc: 0.9296 - val_loss: 0.5017 - val_acc: 0.8410\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1935 - acc: 0.9315 - val_loss: 0.5417 - val_acc: 0.8390\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1892 - acc: 0.9323 - val_loss: 0.5041 - val_acc: 0.8350\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1909 - acc: 0.9306 - val_loss: 0.4909 - val_acc: 0.8420\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1932 - acc: 0.9297 - val_loss: 0.5283 - val_acc: 0.8470\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1783 - acc: 0.9355 - val_loss: 0.5088 - val_acc: 0.8490\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1783 - acc: 0.9361 - val_loss: 0.5403 - val_acc: 0.8450\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1738 - acc: 0.9400 - val_loss: 0.5351 - val_acc: 0.8370\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1693 - acc: 0.9425 - val_loss: 0.5055 - val_acc: 0.8480\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1596 - acc: 0.9438 - val_loss: 0.5319 - val_acc: 0.8430\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1677 - acc: 0.9412 - val_loss: 0.5258 - val_acc: 0.8460\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1485 - acc: 0.9467 - val_loss: 0.5585 - val_acc: 0.8340\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1515 - acc: 0.9470 - val_loss: 0.5308 - val_acc: 0.8420\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1484 - acc: 0.9468 - val_loss: 0.5458 - val_acc: 0.8440\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1393 - acc: 0.9512 - val_loss: 0.5602 - val_acc: 0.8370\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1347 - acc: 0.9538 - val_loss: 0.5625 - val_acc: 0.8360\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1364 - acc: 0.9521 - val_loss: 0.5732 - val_acc: 0.8380\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1377 - acc: 0.9537 - val_loss: 0.5682 - val_acc: 0.8400\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1208 - acc: 0.9626 - val_loss: 0.5495 - val_acc: 0.8480\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1291 - acc: 0.9548 - val_loss: 0.5655 - val_acc: 0.8410\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1148 - acc: 0.9601 - val_loss: 0.5460 - val_acc: 0.8450\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1289 - acc: 0.9571 - val_loss: 0.5458 - val_acc: 0.8430\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1227 - acc: 0.9545 - val_loss: 0.5797 - val_acc: 0.8350\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1154 - acc: 0.9591 - val_loss: 0.6024 - val_acc: 0.8380\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1153 - acc: 0.9614 - val_loss: 0.6593 - val_acc: 0.8380\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1137 - acc: 0.9623 - val_loss: 0.5982 - val_acc: 0.8400\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1176 - acc: 0.9615 - val_loss: 0.5835 - val_acc: 0.8380\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1072 - acc: 0.9646 - val_loss: 0.6717 - val_acc: 0.8340\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1076 - acc: 0.9642 - val_loss: 0.5996 - val_acc: 0.8350\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1178 - acc: 0.9591 - val_loss: 0.6113 - val_acc: 0.8360\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1011 - acc: 0.9670 - val_loss: 0.6551 - val_acc: 0.8400\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0945 - acc: 0.9690 - val_loss: 0.7485 - val_acc: 0.8250\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1038 - acc: 0.9644 - val_loss: 0.6257 - val_acc: 0.8440\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0981 - acc: 0.9639 - val_loss: 0.6331 - val_acc: 0.8440\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1071 - acc: 0.9616 - val_loss: 0.6647 - val_acc: 0.8310\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0913 - acc: 0.9682 - val_loss: 0.6441 - val_acc: 0.8420\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0900 - acc: 0.9696 - val_loss: 0.6371 - val_acc: 0.8400\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0896 - acc: 0.9696 - val_loss: 0.6562 - val_acc: 0.8380\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0820 - acc: 0.9734 - val_loss: 0.6535 - val_acc: 0.8420\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0807 - acc: 0.9721 - val_loss: 0.6983 - val_acc: 0.8340\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0901 - acc: 0.9706 - val_loss: 0.6819 - val_acc: 0.8350\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0857 - acc: 0.9704 - val_loss: 0.7148 - val_acc: 0.8330\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0824 - acc: 0.9705 - val_loss: 0.8131 - val_acc: 0.8270\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0966 - acc: 0.9683 - val_loss: 0.6939 - val_acc: 0.8300\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0832 - acc: 0.9720 - val_loss: 0.6421 - val_acc: 0.8390\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0773 - acc: 0.9708 - val_loss: 0.6999 - val_acc: 0.8330\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0947 - acc: 0.9705 - val_loss: 0.6952 - val_acc: 0.8470\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0699 - acc: 0.9774 - val_loss: 0.6504 - val_acc: 0.8450\n"
     ]
    }
   ],
   "source": [
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# start training the model\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    "\n",
    "# save model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aggregate-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "solar-applicant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                |실제값  |예측값\n",
      "---------------------------------------\n",
      "은경이 는 어디 야 ?        : 복도      복도\n",
      "필웅이 는 어디 야 ?        : 화장실     화장실\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 사무실     화장실\n",
      "수종이 는 어디 야 ?        : 사무실     복도\n",
      "필웅이 는 어디 야 ?        : 부엌      부엌\n",
      "필웅이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      정원\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "은경이 는 어디 야 ?        : 정원      정원\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 사무실     부엌\n",
      "은경이 는 어디 야 ?        : 부엌      복도\n",
      "필웅이 는 어디 야 ?        : 복도      복도\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "수종이 는 어디 야 ?        : 침실      정원\n",
      "경임이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      복도\n"
     ]
    }
   ],
   "source": [
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-layout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
